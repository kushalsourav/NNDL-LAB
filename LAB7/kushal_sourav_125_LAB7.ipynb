{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAB7\n",
    "\n",
    "Name: Kushal Sourav\n",
    "<br />\n",
    "Regno: 2347125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./PoetryFoundationData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Unnamed: 0\n",
      "count  13854.000000\n",
      "mean      93.204417\n",
      "std       57.493544\n",
      "min        0.000000\n",
      "25%       42.000000\n",
      "50%       92.000000\n",
      "75%      142.000000\n",
      "max      199.000000\n"
     ]
    }
   ],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                              Title  \\\n",
      "0           0  \\r\\r\\n                    Objects Used to Prop...   \n",
      "1           1  \\r\\r\\n                    The New Church\\r\\r\\n...   \n",
      "2           2  \\r\\r\\n                    Look for Me\\r\\r\\n   ...   \n",
      "3           3  \\r\\r\\n                    Wild Life\\r\\r\\n     ...   \n",
      "4           4  \\r\\r\\n                    Umbrella\\r\\r\\n      ...   \n",
      "\n",
      "                                                Poem              Poet Tags  \n",
      "0  \\r\\r\\nDog bone, stapler,\\r\\r\\ncribbage board, ...  Michelle Menting  NaN  \n",
      "1  \\r\\r\\nThe old cupola glinted above the clouds,...     Lucia Cherciu  NaN  \n",
      "2  \\r\\r\\nLook for me under the hood\\r\\r\\nof that ...        Ted Kooser  NaN  \n",
      "3  \\r\\r\\nBehind the silo, the Mother Rabbit\\r\\r\\n...   Grace Cavalieri  NaN  \n",
      "4  \\r\\r\\nWhen I push your button\\r\\r\\nyou fly off...      Connie Wanek  NaN  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13854, 5)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13854 entries, 0 to 13853\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  13854 non-null  int64 \n",
      " 1   Title       13854 non-null  object\n",
      " 2   Poem        13854 non-null  object\n",
      " 3   Poet        13854 non-null  object\n",
      " 4   Tags        12899 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 541.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\\n\".join(data['Poem'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus.lower()\n",
    "corpus = re.sub(r'[^\\w\\s]', '', corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([corpus])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Convert text into sequences of integers\n",
    "input_sequences = []\n",
    "corpus_words = corpus.split()\n",
    "for i in range(5, len(corpus_words)):\n",
    "    sequence = corpus_words[i-5:i+1]\n",
    "    tokenized_seq = tokenizer.texts_to_sequences([\" \".join(sequence)])[0]\n",
    "    input_sequences.append(tokenized_seq)\n",
    "\n",
    "# Pad sequences\n",
    "max_sequence_len = 5  # length of each sequence\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "X, y = X[:10000], y[:10000]\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=total_words, output_dim=100, input_length=max_sequence_len))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(total_words, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 1s/step - accuracy: 0.0611 - loss: 11.4866\n",
      "Epoch 2/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 1s/step - accuracy: 0.0700 - loss: 7.1831\n",
      "Epoch 3/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 1s/step - accuracy: 0.0715 - loss: 6.8709\n",
      "Epoch 4/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.0685 - loss: 6.7412\n",
      "Epoch 5/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 1s/step - accuracy: 0.0728 - loss: 6.6478\n",
      "Epoch 6/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.0720 - loss: 6.5806\n",
      "Epoch 7/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.0730 - loss: 6.5769\n",
      "Epoch 8/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.0658 - loss: 6.5776\n",
      "Epoch 9/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 1s/step - accuracy: 0.0718 - loss: 6.5145\n",
      "Epoch 10/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.0746 - loss: 6.5027\n",
      "Epoch 11/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.0730 - loss: 6.4584\n",
      "Epoch 12/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.0717 - loss: 6.4738\n",
      "Epoch 13/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1s/step - accuracy: 0.0721 - loss: 6.3878\n",
      "Epoch 14/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 1s/step - accuracy: 0.0723 - loss: 6.2694\n",
      "Epoch 15/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 1s/step - accuracy: 0.0683 - loss: 6.2925\n",
      "Epoch 16/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 1s/step - accuracy: 0.0720 - loss: 6.1667\n",
      "Epoch 17/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 1s/step - accuracy: 0.0701 - loss: 6.0604\n",
      "Epoch 18/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 1s/step - accuracy: 0.0736 - loss: 6.0141\n",
      "Epoch 19/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1s/step - accuracy: 0.0730 - loss: 5.9294\n",
      "Epoch 20/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.0756 - loss: 5.8962\n",
      "Epoch 21/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 1s/step - accuracy: 0.0702 - loss: 5.8566\n",
      "Epoch 22/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1s/step - accuracy: 0.0710 - loss: 5.7648\n",
      "Epoch 23/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1s/step - accuracy: 0.0718 - loss: 5.7368\n",
      "Epoch 24/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 1s/step - accuracy: 0.0789 - loss: 5.6473\n",
      "Epoch 25/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.0773 - loss: 5.6052\n",
      "Epoch 26/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1s/step - accuracy: 0.0825 - loss: 5.5511\n",
      "Epoch 27/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1s/step - accuracy: 0.0807 - loss: 5.5099\n",
      "Epoch 28/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.0847 - loss: 5.4542\n",
      "Epoch 29/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 1s/step - accuracy: 0.0879 - loss: 5.4085\n",
      "Epoch 30/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 1s/step - accuracy: 0.0952 - loss: 5.3137\n",
      "Epoch 31/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.0981 - loss: 5.3002\n",
      "Epoch 32/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 1s/step - accuracy: 0.0977 - loss: 5.2499\n",
      "Epoch 33/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.0994 - loss: 5.2025\n",
      "Epoch 34/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.1078 - loss: 5.1263\n",
      "Epoch 35/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 1s/step - accuracy: 0.1070 - loss: 5.0803\n",
      "Epoch 36/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 1s/step - accuracy: 0.1186 - loss: 5.0134\n",
      "Epoch 37/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.1125 - loss: 4.9919\n",
      "Epoch 38/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.1240 - loss: 4.9412\n",
      "Epoch 39/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.1254 - loss: 4.8659\n",
      "Epoch 40/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.1346 - loss: 4.8210\n",
      "Epoch 41/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.1336 - loss: 4.7920\n",
      "Epoch 42/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.1413 - loss: 4.7068\n",
      "Epoch 43/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 1s/step - accuracy: 0.1474 - loss: 4.6701\n",
      "Epoch 44/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.1403 - loss: 4.6403\n",
      "Epoch 45/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 1s/step - accuracy: 0.1442 - loss: 4.6171\n",
      "Epoch 46/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.1523 - loss: 4.5310\n",
      "Epoch 47/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.1561 - loss: 4.4950\n",
      "Epoch 48/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 1s/step - accuracy: 0.1559 - loss: 4.4816\n",
      "Epoch 49/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 1s/step - accuracy: 0.1648 - loss: 4.3937\n",
      "Epoch 50/50\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - accuracy: 0.1598 - loss: 4.4085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a2df9e5390>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=50, batch_size =128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Morning Sun Shine his way is the dead of\n"
     ]
    }
   ],
   "source": [
    "def generate_poetry(seed_text, next_words=5000):\n",
    "    generated_words = set()\n",
    "    poem = seed_text\n",
    "\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([poem])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len, padding='pre')\n",
    "\n",
    "        predicted_probs = model.predict(token_list, verbose=0)\n",
    "        predicted = np.argmax(predicted_probs, axis=-1)\n",
    "\n",
    "        next_word = tokenizer.index_word.get(predicted[0], None)\n",
    "        if next_word is None or next_word in generated_words:\n",
    "            continue\n",
    "\n",
    "        generated_words.add(next_word)\n",
    "        poem += \" \" + next_word\n",
    "\n",
    "    return poem\n",
    "\n",
    "print(generate_poetry(\"The Morning Sun Shine\", next_words=500))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Morning Sun Shine his way is the dead of\n"
     ]
    }
   ],
   "source": [
    "def generate_poetry(seed_text, next_words=5000, words_per_line=10):\n",
    "    generated_words = set()\n",
    "    poem = seed_text\n",
    "\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([poem])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len, padding='pre')\n",
    "\n",
    "        predicted_probs = model.predict(token_list, verbose=0)\n",
    "        predicted = np.argmax(predicted_probs, axis=-1)\n",
    "\n",
    "        next_word = tokenizer.index_word.get(predicted[0], None)\n",
    "        if next_word is None or next_word in generated_words:\n",
    "            continue\n",
    "\n",
    "        generated_words.add(next_word)\n",
    "        poem += \" \" + next_word\n",
    "\n",
    "    return poem\n",
    "\n",
    "print(generate_poetry(\"The Morning Sun Shine\", next_words=500))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: the moonlight whispers\n",
      "the moonlight whispers that faces in one look like\n",
      "\n",
      "==================================================\n",
      "\n",
      "Seed: in the quiet of night\n",
      "in the quiet of night that ride of her will is still in the way and are days as\n",
      "\n",
      "==================================================\n",
      "\n",
      "Seed: stars shine brightly\n",
      "stars shine brightly its long juice and these gods from\n",
      "\n",
      "==================================================\n",
      "\n",
      "Seed: a gentle breeze flows\n",
      "a gentle breeze flows in is\n",
      "\n",
      "==================================================\n",
      "\n",
      "Seed: echoes in silence\n",
      "echoes in silence and are the map one left as ride\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate multiple lines of poetry using different starting phrases\n",
    "seed_texts = [\"the moonlight whispers\", \"in the quiet of night\", \"stars shine brightly\", \"a gentle breeze flows\", \"echoes in silence\"]\n",
    "\n",
    "for seed in seed_texts:\n",
    "    print(f\"Seed: {seed}\")\n",
    "    print(generate_poetry(seed, next_words=100, words_per_line=100))\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
